{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Despise me, if I do not. Three great ones of the city,\n",
    "In personal suit to make me his lieutenant,\n",
    "Off-capp'd to him: and, by the faith of man,\n",
    "I know my price, I am worth no worse a place:\n",
    "But he; as loving his own pride and purposes,\n",
    "Evades them, with a bombast circumstance\n",
    "Horribly stuff'd with epithets of war;\n",
    "And, in conclusion,\n",
    "Nonsuits my mediators; for, 'Certes,' says he,\n",
    "'I have already chose my officer.'\n",
    "And what was he?\n",
    "Forsooth, a great arithmetician,\n",
    "One Michael Cassio, a Florentine,\n",
    "A fellow almost damn'd in a fair wife;\n",
    "That never set a squadron in the field,\n",
    "Nor the division of a battle knows\n",
    "More than a spinster; unless the bookish theoric,\n",
    "Wherein the toged consuls can propose\n",
    "As masterly as he: mere prattle, without practise,\n",
    "Is all his soldiership. But he, sir, had the election:\n",
    "And I, of whom his eyes had seen the proof\n",
    "At Rhodes, at Cyprus and on other grounds\n",
    "Christian and heathen, must be be-lee'd and calm'd\n",
    "By debitor and creditor: this counter-caster,\n",
    "He, in good time, must his lieutenant be,\n",
    "And I--God bless the mark!--his Moorship's ancient.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Processing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "punctuation = string.punctuation\n",
    "print(punctuation)\n",
    "stop = stopwords.words('english')\n",
    "print(stop[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = \"\".join([j for j in corpus[i] if j not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_seq = token_list[:i+1]\n",
    "        input_sequence.append(n_gram_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max([len(x) for x in input_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = pad_sequences(input_sequence,maxlen=max_seq_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  22,  11],\n",
       "       [  0,   0,   0, ...,  22,  11,  23],\n",
       "       [  0,   0,   0, ...,  11,  23,   5],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 128,   2, 129],\n",
       "       [  0,   0,   0, ...,   2, 129, 130],\n",
       "       [  0,   0,   0, ..., 129, 130, 131]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = input_sequence[:,:-1]\n",
    "labels = input_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tf.keras.utils.to_categorical(labels,num_classes=total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(total_word,64,input_length= max_seq_len - 1),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(total_word,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166 samples\n",
      "Epoch 1/500\n",
      "166/166 [==============================] - 9s 54ms/sample - loss: 4.8830 - acc: 0.0120\n",
      "Epoch 2/500\n",
      "166/166 [==============================] - 0s 655us/sample - loss: 4.8727 - acc: 0.0422\n",
      "Epoch 3/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 4.8637 - acc: 0.0482\n",
      "Epoch 4/500\n",
      "166/166 [==============================] - 0s 595us/sample - loss: 4.8533 - acc: 0.0663\n",
      "Epoch 5/500\n",
      "166/166 [==============================] - 0s 667us/sample - loss: 4.8402 - acc: 0.0783\n",
      "Epoch 6/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 4.8221 - acc: 0.0783\n",
      "Epoch 7/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 4.7964 - acc: 0.0602\n",
      "Epoch 8/500\n",
      "166/166 [==============================] - 0s 682us/sample - loss: 4.7573 - acc: 0.0663\n",
      "Epoch 9/500\n",
      "166/166 [==============================] - 0s 595us/sample - loss: 4.7058 - acc: 0.0663\n",
      "Epoch 10/500\n",
      "166/166 [==============================] - 0s 719us/sample - loss: 4.6454 - acc: 0.0602\n",
      "Epoch 11/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 4.5985 - acc: 0.0542\n",
      "Epoch 12/500\n",
      "166/166 [==============================] - 0s 751us/sample - loss: 4.5654 - acc: 0.0542\n",
      "Epoch 13/500\n",
      "166/166 [==============================] - 0s 496us/sample - loss: 4.5399 - acc: 0.0542\n",
      "Epoch 14/500\n",
      "166/166 [==============================] - 0s 556us/sample - loss: 4.5195 - acc: 0.0542\n",
      "Epoch 15/500\n",
      "166/166 [==============================] - 0s 562us/sample - loss: 4.4972 - acc: 0.0602\n",
      "Epoch 16/500\n",
      "166/166 [==============================] - 0s 568us/sample - loss: 4.4766 - acc: 0.0783\n",
      "Epoch 17/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 4.4546 - acc: 0.0663\n",
      "Epoch 18/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 4.4286 - acc: 0.0663\n",
      "Epoch 19/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 4.4003 - acc: 0.1024\n",
      "Epoch 20/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 4.3681 - acc: 0.0964\n",
      "Epoch 21/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 4.3353 - acc: 0.0843\n",
      "Epoch 22/500\n",
      "166/166 [==============================] - 0s 580us/sample - loss: 4.2998 - acc: 0.0904\n",
      "Epoch 23/500\n",
      "166/166 [==============================] - 0s 547us/sample - loss: 4.2563 - acc: 0.1145\n",
      "Epoch 24/500\n",
      "166/166 [==============================] - 0s 550us/sample - loss: 4.2170 - acc: 0.1145\n",
      "Epoch 25/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 4.1741 - acc: 0.1084\n",
      "Epoch 26/500\n",
      "166/166 [==============================] - 0s 652us/sample - loss: 4.1340 - acc: 0.1024\n",
      "Epoch 27/500\n",
      "166/166 [==============================] - 0s 541us/sample - loss: 4.0900 - acc: 0.1084\n",
      "Epoch 28/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 4.0388 - acc: 0.1145\n",
      "Epoch 29/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 3.9920 - acc: 0.1265\n",
      "Epoch 30/500\n",
      "166/166 [==============================] - 0s 604us/sample - loss: 3.9423 - acc: 0.1446\n",
      "Epoch 31/500\n",
      "166/166 [==============================] - 0s 574us/sample - loss: 3.8938 - acc: 0.1506\n",
      "Epoch 32/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 3.8479 - acc: 0.1566\n",
      "Epoch 33/500\n",
      "166/166 [==============================] - 0s 580us/sample - loss: 3.7998 - acc: 0.1627\n",
      "Epoch 34/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 3.7403 - acc: 0.1747\n",
      "Epoch 35/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 3.6863 - acc: 0.1687\n",
      "Epoch 36/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 3.6385 - acc: 0.1687\n",
      "Epoch 37/500\n",
      "166/166 [==============================] - 0s 541us/sample - loss: 3.5939 - acc: 0.1687\n",
      "Epoch 38/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 3.5442 - acc: 0.1807\n",
      "Epoch 39/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 3.4986 - acc: 0.1807\n",
      "Epoch 40/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 3.4559 - acc: 0.1928\n",
      "Epoch 41/500\n",
      "166/166 [==============================] - 0s 556us/sample - loss: 3.4056 - acc: 0.1988\n",
      "Epoch 42/500\n",
      "166/166 [==============================] - 0s 721us/sample - loss: 3.3644 - acc: 0.2108\n",
      "Epoch 43/500\n",
      "166/166 [==============================] - 0s 555us/sample - loss: 3.3243 - acc: 0.2108\n",
      "Epoch 44/500\n",
      "166/166 [==============================] - 0s 568us/sample - loss: 3.2856 - acc: 0.2108\n",
      "Epoch 45/500\n",
      "166/166 [==============================] - 0s 607us/sample - loss: 3.2428 - acc: 0.2289\n",
      "Epoch 46/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 3.2015 - acc: 0.2349\n",
      "Epoch 47/500\n",
      "166/166 [==============================] - 0s 481us/sample - loss: 3.1692 - acc: 0.2470\n",
      "Epoch 48/500\n",
      "166/166 [==============================] - 0s 602us/sample - loss: 3.1259 - acc: 0.2410\n",
      "Epoch 49/500\n",
      "166/166 [==============================] - 0s 574us/sample - loss: 3.0978 - acc: 0.2590\n",
      "Epoch 50/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 3.0626 - acc: 0.2711\n",
      "Epoch 51/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 3.0379 - acc: 0.2952\n",
      "Epoch 52/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 2.9878 - acc: 0.2892\n",
      "Epoch 53/500\n",
      "166/166 [==============================] - 0s 541us/sample - loss: 2.9460 - acc: 0.2892\n",
      "Epoch 54/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 2.9166 - acc: 0.3193\n",
      "Epoch 55/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 2.8805 - acc: 0.3253\n",
      "Epoch 56/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 2.8478 - acc: 0.3133\n",
      "Epoch 57/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 2.8377 - acc: 0.3193\n",
      "Epoch 58/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 2.7919 - acc: 0.3253\n",
      "Epoch 59/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 2.7538 - acc: 0.3373\n",
      "Epoch 60/500\n",
      "166/166 [==============================] - 0s 534us/sample - loss: 2.7260 - acc: 0.3253\n",
      "Epoch 61/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 2.7030 - acc: 0.3313\n",
      "Epoch 62/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 2.6842 - acc: 0.3554s - loss: 2.6761 - acc: 0.356\n",
      "Epoch 63/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 2.6464 - acc: 0.3675\n",
      "Epoch 64/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 2.6256 - acc: 0.3614\n",
      "Epoch 65/500\n",
      "166/166 [==============================] - 0s 532us/sample - loss: 2.6021 - acc: 0.3735\n",
      "Epoch 66/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 2.5745 - acc: 0.3735\n",
      "Epoch 67/500\n",
      "166/166 [==============================] - 0s 550us/sample - loss: 2.5370 - acc: 0.3916\n",
      "Epoch 68/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 2.5020 - acc: 0.3855\n",
      "Epoch 69/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 2.4786 - acc: 0.3976\n",
      "Epoch 70/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 2.4555 - acc: 0.3795\n",
      "Epoch 71/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 2.4380 - acc: 0.3855\n",
      "Epoch 72/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 2.4038 - acc: 0.4157\n",
      "Epoch 73/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 2.3899 - acc: 0.4036\n",
      "Epoch 74/500\n",
      "166/166 [==============================] - 0s 520us/sample - loss: 2.3865 - acc: 0.4036\n",
      "Epoch 75/500\n",
      "166/166 [==============================] - 0s 451us/sample - loss: 2.3420 - acc: 0.4277\n",
      "Epoch 76/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 2.3054 - acc: 0.4157\n",
      "Epoch 77/500\n",
      "166/166 [==============================] - 0s 412us/sample - loss: 2.2879 - acc: 0.4699\n",
      "Epoch 78/500\n",
      "166/166 [==============================] - 0s 487us/sample - loss: 2.2629 - acc: 0.4699\n",
      "Epoch 79/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 2.2397 - acc: 0.4819\n",
      "Epoch 80/500\n",
      "166/166 [==============================] - 0s 547us/sample - loss: 2.2160 - acc: 0.4940\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 522us/sample - loss: 2.1910 - acc: 0.5060\n",
      "Epoch 82/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 2.1664 - acc: 0.5181\n",
      "Epoch 83/500\n",
      "166/166 [==============================] - 0s 556us/sample - loss: 2.1482 - acc: 0.4880\n",
      "Epoch 84/500\n",
      "166/166 [==============================] - 0s 496us/sample - loss: 2.1225 - acc: 0.5181\n",
      "Epoch 85/500\n",
      "166/166 [==============================] - 0s 472us/sample - loss: 2.0989 - acc: 0.5181\n",
      "Epoch 86/500\n",
      "166/166 [==============================] - 0s 454us/sample - loss: 2.0759 - acc: 0.5301\n",
      "Epoch 87/500\n",
      "166/166 [==============================] - 0s 532us/sample - loss: 2.0484 - acc: 0.5422\n",
      "Epoch 88/500\n",
      "166/166 [==============================] - 0s 520us/sample - loss: 2.0280 - acc: 0.5663\n",
      "Epoch 89/500\n",
      "166/166 [==============================] - 0s 538us/sample - loss: 2.0057 - acc: 0.5723\n",
      "Epoch 90/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 1.9837 - acc: 0.5783\n",
      "Epoch 91/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 1.9704 - acc: 0.6084\n",
      "Epoch 92/500\n",
      "166/166 [==============================] - 0s 475us/sample - loss: 1.9435 - acc: 0.6265\n",
      "Epoch 93/500\n",
      "166/166 [==============================] - 0s 487us/sample - loss: 1.9351 - acc: 0.6145\n",
      "Epoch 94/500\n",
      "166/166 [==============================] - 0s 588us/sample - loss: 1.9567 - acc: 0.6386\n",
      "Epoch 95/500\n",
      "166/166 [==============================] - 0s 533us/sample - loss: 1.9371 - acc: 0.6325\n",
      "Epoch 96/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 1.9226 - acc: 0.6145\n",
      "Epoch 97/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 1.9034 - acc: 0.6205\n",
      "Epoch 98/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 1.8647 - acc: 0.6627\n",
      "Epoch 99/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 1.8403 - acc: 0.6627\n",
      "Epoch 100/500\n",
      "166/166 [==============================] - 0s 556us/sample - loss: 1.8292 - acc: 0.6446\n",
      "Epoch 101/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 1.8183 - acc: 0.6627\n",
      "Epoch 102/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 1.7969 - acc: 0.6747\n",
      "Epoch 103/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 1.7731 - acc: 0.6627\n",
      "Epoch 104/500\n",
      "166/166 [==============================] - 0s 450us/sample - loss: 1.7495 - acc: 0.6747\n",
      "Epoch 105/500\n",
      "166/166 [==============================] - 0s 502us/sample - loss: 1.7301 - acc: 0.6928\n",
      "Epoch 106/500\n",
      "166/166 [==============================] - 0s 568us/sample - loss: 1.7144 - acc: 0.6928\n",
      "Epoch 107/500\n",
      "166/166 [==============================] - 0s 481us/sample - loss: 1.6984 - acc: 0.6928\n",
      "Epoch 108/500\n",
      "166/166 [==============================] - 0s 514us/sample - loss: 1.6865 - acc: 0.7108\n",
      "Epoch 109/500\n",
      "166/166 [==============================] - 0s 526us/sample - loss: 1.6673 - acc: 0.7108\n",
      "Epoch 110/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 1.6542 - acc: 0.7169\n",
      "Epoch 111/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 1.6425 - acc: 0.7289\n",
      "Epoch 112/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 1.6202 - acc: 0.7289\n",
      "Epoch 113/500\n",
      "166/166 [==============================] - 0s 841us/sample - loss: 1.6066 - acc: 0.7410\n",
      "Epoch 114/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 1.5859 - acc: 0.7470\n",
      "Epoch 115/500\n",
      "166/166 [==============================] - 0s 721us/sample - loss: 1.5710 - acc: 0.7349\n",
      "Epoch 116/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 1.5529 - acc: 0.7530\n",
      "Epoch 117/500\n",
      "166/166 [==============================] - 0s 691us/sample - loss: 1.5397 - acc: 0.7590\n",
      "Epoch 118/500\n",
      "166/166 [==============================] - 0s 763us/sample - loss: 1.5264 - acc: 0.7651\n",
      "Epoch 119/500\n",
      "166/166 [==============================] - 0s 648us/sample - loss: 1.5131 - acc: 0.7771\n",
      "Epoch 120/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 1.4981 - acc: 0.7590\n",
      "Epoch 121/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 1.4870 - acc: 0.7831\n",
      "Epoch 122/500\n",
      "166/166 [==============================] - 0s 769us/sample - loss: 1.4737 - acc: 0.7651\n",
      "Epoch 123/500\n",
      "166/166 [==============================] - 0s 697us/sample - loss: 1.4565 - acc: 0.7952\n",
      "Epoch 124/500\n",
      "166/166 [==============================] - 0s 667us/sample - loss: 1.4449 - acc: 0.8012\n",
      "Epoch 125/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 1.4277 - acc: 0.8012\n",
      "Epoch 126/500\n",
      "166/166 [==============================] - 0s 703us/sample - loss: 1.4179 - acc: 0.7892\n",
      "Epoch 127/500\n",
      "166/166 [==============================] - 0s 679us/sample - loss: 1.4144 - acc: 0.8072\n",
      "Epoch 128/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 1.3898 - acc: 0.8133\n",
      "Epoch 129/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 1.3787 - acc: 0.8133\n",
      "Epoch 130/500\n",
      "166/166 [==============================] - 0s 619us/sample - loss: 1.3663 - acc: 0.8313\n",
      "Epoch 131/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 1.3498 - acc: 0.8253\n",
      "Epoch 132/500\n",
      "166/166 [==============================] - 0s 805us/sample - loss: 1.3371 - acc: 0.8133\n",
      "Epoch 133/500\n",
      "166/166 [==============================] - 0s 751us/sample - loss: 1.3253 - acc: 0.8253\n",
      "Epoch 134/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 1.3154 - acc: 0.8313\n",
      "Epoch 135/500\n",
      "166/166 [==============================] - 0s 667us/sample - loss: 1.3105 - acc: 0.8193\n",
      "Epoch 136/500\n",
      "166/166 [==============================] - 0s 865us/sample - loss: 1.3071 - acc: 0.8193\n",
      "Epoch 137/500\n",
      "166/166 [==============================] - 0s 667us/sample - loss: 1.2926 - acc: 0.8434\n",
      "Epoch 138/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 1.2754 - acc: 0.8373\n",
      "Epoch 139/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 1.2671 - acc: 0.8494\n",
      "Epoch 140/500\n",
      "166/166 [==============================] - 0s 793us/sample - loss: 1.2501 - acc: 0.8735\n",
      "Epoch 141/500\n",
      "166/166 [==============================] - 0s 919us/sample - loss: 1.2381 - acc: 0.8735\n",
      "Epoch 142/500\n",
      "166/166 [==============================] - 0s 709us/sample - loss: 1.2246 - acc: 0.8614\n",
      "Epoch 143/500\n",
      "166/166 [==============================] - 0s 649us/sample - loss: 1.2123 - acc: 0.8735\n",
      "Epoch 144/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 1.2043 - acc: 0.8675\n",
      "Epoch 145/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 1.1953 - acc: 0.8735\n",
      "Epoch 146/500\n",
      "166/166 [==============================] - 0s 643us/sample - loss: 1.1818 - acc: 0.8675\n",
      "Epoch 147/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 1.1744 - acc: 0.8675\n",
      "Epoch 148/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 1.1695 - acc: 0.8675\n",
      "Epoch 149/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 1.1522 - acc: 0.8795\n",
      "Epoch 150/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 1.1395 - acc: 0.8795\n",
      "Epoch 151/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 1.1299 - acc: 0.8795\n",
      "Epoch 152/500\n",
      "166/166 [==============================] - 0s 691us/sample - loss: 1.1204 - acc: 0.8855\n",
      "Epoch 153/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 1.1066 - acc: 0.8976\n",
      "Epoch 154/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 1.0980 - acc: 0.9036\n",
      "Epoch 155/500\n",
      "166/166 [==============================] - 0s 445us/sample - loss: 1.0871 - acc: 0.9157\n",
      "Epoch 156/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 1.0790 - acc: 0.9157\n",
      "Epoch 157/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 1.0684 - acc: 0.9217\n",
      "Epoch 158/500\n",
      "166/166 [==============================] - 0s 625us/sample - loss: 1.0596 - acc: 0.9277\n",
      "Epoch 159/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 1.0504 - acc: 0.9217\n",
      "Epoch 160/500\n",
      "166/166 [==============================] - 0s 661us/sample - loss: 1.0425 - acc: 0.9217\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 613us/sample - loss: 1.0688 - acc: 0.9036\n",
      "Epoch 162/500\n",
      "166/166 [==============================] - 0s 733us/sample - loss: 1.0804 - acc: 0.8976\n",
      "Epoch 163/500\n",
      "166/166 [==============================] - 0s 751us/sample - loss: 1.0479 - acc: 0.8976\n",
      "Epoch 164/500\n",
      "166/166 [==============================] - 0s 823us/sample - loss: 1.0256 - acc: 0.8976\n",
      "Epoch 165/500\n",
      "166/166 [==============================] - 0s 697us/sample - loss: 1.0150 - acc: 0.9157\n",
      "Epoch 166/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.9996 - acc: 0.9157\n",
      "Epoch 167/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.9898 - acc: 0.9096\n",
      "Epoch 168/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.9819 - acc: 0.9157\n",
      "Epoch 169/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.9735 - acc: 0.9096\n",
      "Epoch 170/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.9623 - acc: 0.9277s - loss: 0.9580 - acc: 0.931\n",
      "Epoch 171/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.9610 - acc: 0.9337\n",
      "Epoch 172/500\n",
      "166/166 [==============================] - 0s 727us/sample - loss: 0.9596 - acc: 0.9157\n",
      "Epoch 173/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.9557 - acc: 0.9217\n",
      "Epoch 174/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.9440 - acc: 0.9217\n",
      "Epoch 175/500\n",
      "166/166 [==============================] - 0s 751us/sample - loss: 0.9278 - acc: 0.9277\n",
      "Epoch 176/500\n",
      "166/166 [==============================] - 0s 655us/sample - loss: 0.9221 - acc: 0.9458\n",
      "Epoch 177/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 0.9147 - acc: 0.9337\n",
      "Epoch 178/500\n",
      "166/166 [==============================] - 0s 655us/sample - loss: 0.8956 - acc: 0.9398\n",
      "Epoch 179/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 0.8957 - acc: 0.9337\n",
      "Epoch 180/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.8831 - acc: 0.9337\n",
      "Epoch 181/500\n",
      "166/166 [==============================] - 0s 655us/sample - loss: 0.8731 - acc: 0.9337\n",
      "Epoch 182/500\n",
      "166/166 [==============================] - 0s 691us/sample - loss: 0.8706 - acc: 0.9398\n",
      "Epoch 183/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.8609 - acc: 0.9398\n",
      "Epoch 184/500\n",
      "166/166 [==============================] - 0s 625us/sample - loss: 0.8517 - acc: 0.9398\n",
      "Epoch 185/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.8442 - acc: 0.9458\n",
      "Epoch 186/500\n",
      "166/166 [==============================] - 0s 481us/sample - loss: 0.8384 - acc: 0.9398\n",
      "Epoch 187/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 0.8331 - acc: 0.9518\n",
      "Epoch 188/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.8260 - acc: 0.9458\n",
      "Epoch 189/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.8150 - acc: 0.9639\n",
      "Epoch 190/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 0.8101 - acc: 0.9518\n",
      "Epoch 191/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.8013 - acc: 0.9398\n",
      "Epoch 192/500\n",
      "166/166 [==============================] - 0s 655us/sample - loss: 0.8010 - acc: 0.9458\n",
      "Epoch 193/500\n",
      "166/166 [==============================] - 0s 697us/sample - loss: 0.7894 - acc: 0.9518\n",
      "Epoch 194/500\n",
      "166/166 [==============================] - 0s 859us/sample - loss: 0.7844 - acc: 0.9398\n",
      "Epoch 195/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 0.7754 - acc: 0.9458\n",
      "Epoch 196/500\n",
      "166/166 [==============================] - 0s 643us/sample - loss: 0.7708 - acc: 0.9398\n",
      "Epoch 197/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.7640 - acc: 0.9458\n",
      "Epoch 198/500\n",
      "166/166 [==============================] - 0s 703us/sample - loss: 0.7548 - acc: 0.9458\n",
      "Epoch 199/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 0.7496 - acc: 0.9518\n",
      "Epoch 200/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.7427 - acc: 0.9518\n",
      "Epoch 201/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 0.7367 - acc: 0.9518\n",
      "Epoch 202/500\n",
      "166/166 [==============================] - 0s 643us/sample - loss: 0.7315 - acc: 0.9639\n",
      "Epoch 203/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 0.7256 - acc: 0.9639\n",
      "Epoch 204/500\n",
      "166/166 [==============================] - 0s 679us/sample - loss: 0.7208 - acc: 0.9458\n",
      "Epoch 205/500\n",
      "166/166 [==============================] - 0s 595us/sample - loss: 0.7137 - acc: 0.9639\n",
      "Epoch 206/500\n",
      "166/166 [==============================] - 0s 607us/sample - loss: 0.7074 - acc: 0.9639\n",
      "Epoch 207/500\n",
      "166/166 [==============================] - 0s 631us/sample - loss: 0.7024 - acc: 0.9518\n",
      "Epoch 208/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 0.6951 - acc: 0.9639\n",
      "Epoch 209/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.6905 - acc: 0.9518\n",
      "Epoch 210/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 0.6899 - acc: 0.9578\n",
      "Epoch 211/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.6821 - acc: 0.9578\n",
      "Epoch 212/500\n",
      "166/166 [==============================] - 0s 697us/sample - loss: 0.6773 - acc: 0.9518\n",
      "Epoch 213/500\n",
      "166/166 [==============================] - 0s 697us/sample - loss: 0.6695 - acc: 0.9639\n",
      "Epoch 214/500\n",
      "166/166 [==============================] - 0s 679us/sample - loss: 0.6632 - acc: 0.9578\n",
      "Epoch 215/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.6579 - acc: 0.9578\n",
      "Epoch 216/500\n",
      "166/166 [==============================] - 0s 643us/sample - loss: 0.6549 - acc: 0.9578\n",
      "Epoch 217/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.6483 - acc: 0.9578\n",
      "Epoch 218/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.6427 - acc: 0.9578\n",
      "Epoch 219/500\n",
      "166/166 [==============================] - 0s 739us/sample - loss: 0.6366 - acc: 0.9578\n",
      "Epoch 220/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 0.6330 - acc: 0.9578\n",
      "Epoch 221/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 0.6292 - acc: 0.9578\n",
      "Epoch 222/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.6226 - acc: 0.9578\n",
      "Epoch 223/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.6185 - acc: 0.9578\n",
      "Epoch 224/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 0.6135 - acc: 0.9578\n",
      "Epoch 225/500\n",
      "166/166 [==============================] - 0s 595us/sample - loss: 0.6090 - acc: 0.9578\n",
      "Epoch 226/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 0.6039 - acc: 0.9578\n",
      "Epoch 227/500\n",
      "166/166 [==============================] - 0s 607us/sample - loss: 0.6004 - acc: 0.9578\n",
      "Epoch 228/500\n",
      "166/166 [==============================] - 0s 631us/sample - loss: 0.5945 - acc: 0.9578\n",
      "Epoch 229/500\n",
      "166/166 [==============================] - 0s 829us/sample - loss: 0.5889 - acc: 0.9578\n",
      "Epoch 230/500\n",
      "166/166 [==============================] - 0s 697us/sample - loss: 0.5848 - acc: 0.9578\n",
      "Epoch 231/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 0.5798 - acc: 0.9578\n",
      "Epoch 232/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.5761 - acc: 0.9578\n",
      "Epoch 233/500\n",
      "166/166 [==============================] - 0s 607us/sample - loss: 0.5709 - acc: 0.9578\n",
      "Epoch 234/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.5663 - acc: 0.9639\n",
      "Epoch 235/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 0.5630 - acc: 0.9699\n",
      "Epoch 236/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.5585 - acc: 0.9699\n",
      "Epoch 237/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 0.5546 - acc: 0.9639\n",
      "Epoch 238/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.5496 - acc: 0.9639\n",
      "Epoch 239/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.5482 - acc: 0.9699\n",
      "Epoch 240/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 0.5420 - acc: 0.9699\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 517us/sample - loss: 0.5404 - acc: 0.9639\n",
      "Epoch 242/500\n",
      "166/166 [==============================] - 0s 703us/sample - loss: 0.5335 - acc: 0.9639\n",
      "Epoch 243/500\n",
      "166/166 [==============================] - 0s 709us/sample - loss: 0.5302 - acc: 0.9518\n",
      "Epoch 244/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 0.5248 - acc: 0.9699\n",
      "Epoch 245/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.5221 - acc: 0.9639\n",
      "Epoch 246/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.5180 - acc: 0.9639\n",
      "Epoch 247/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.5143 - acc: 0.9639\n",
      "Epoch 248/500\n",
      "166/166 [==============================] - 0s 661us/sample - loss: 0.5099 - acc: 0.9639\n",
      "Epoch 249/500\n",
      "166/166 [==============================] - 0s 715us/sample - loss: 0.5077 - acc: 0.9639\n",
      "Epoch 250/500\n",
      "166/166 [==============================] - 0s 487us/sample - loss: 0.5030 - acc: 0.9759\n",
      "Epoch 251/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 0.4991 - acc: 0.9699\n",
      "Epoch 252/500\n",
      "166/166 [==============================] - 0s 481us/sample - loss: 0.4962 - acc: 0.9639\n",
      "Epoch 253/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 0.4920 - acc: 0.9699\n",
      "Epoch 254/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.4886 - acc: 0.9699\n",
      "Epoch 255/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.4865 - acc: 0.9578\n",
      "Epoch 256/500\n",
      "166/166 [==============================] - 0s 2ms/sample - loss: 0.4825 - acc: 0.9639\n",
      "Epoch 257/500\n",
      "166/166 [==============================] - 0s 943us/sample - loss: 0.4788 - acc: 0.9699\n",
      "Epoch 258/500\n",
      "166/166 [==============================] - 0s 649us/sample - loss: 0.4765 - acc: 0.9699\n",
      "Epoch 259/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 0.4719 - acc: 0.9699\n",
      "Epoch 260/500\n",
      "166/166 [==============================] - 0s 848us/sample - loss: 0.4675 - acc: 0.9759\n",
      "Epoch 261/500\n",
      "166/166 [==============================] - 0s 903us/sample - loss: 0.4651 - acc: 0.9699\n",
      "Epoch 262/500\n",
      "166/166 [==============================] - 0s 841us/sample - loss: 0.4623 - acc: 0.9699\n",
      "Epoch 263/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 0.4588 - acc: 0.9699\n",
      "Epoch 264/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 0.4562 - acc: 0.9639\n",
      "Epoch 265/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 0.4515 - acc: 0.9759\n",
      "Epoch 266/500\n",
      "166/166 [==============================] - 0s 765us/sample - loss: 0.4491 - acc: 0.9759\n",
      "Epoch 267/500\n",
      "166/166 [==============================] - 0s 833us/sample - loss: 0.4454 - acc: 0.9759\n",
      "Epoch 268/500\n",
      "166/166 [==============================] - 0s 868us/sample - loss: 0.4431 - acc: 0.9759\n",
      "Epoch 269/500\n",
      "166/166 [==============================] - 0s 672us/sample - loss: 0.4395 - acc: 0.9759\n",
      "Epoch 270/500\n",
      "166/166 [==============================] - 0s 793us/sample - loss: 0.4353 - acc: 0.9759\n",
      "Epoch 271/500\n",
      "166/166 [==============================] - 0s 779us/sample - loss: 0.4344 - acc: 0.9759\n",
      "Epoch 272/500\n",
      "166/166 [==============================] - 0s 817us/sample - loss: 0.4309 - acc: 0.9759\n",
      "Epoch 273/500\n",
      "166/166 [==============================] - 0s 799us/sample - loss: 0.4281 - acc: 0.9759\n",
      "Epoch 274/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 0.4251 - acc: 0.9759\n",
      "Epoch 275/500\n",
      "166/166 [==============================] - 0s 813us/sample - loss: 0.4212 - acc: 0.9759\n",
      "Epoch 276/500\n",
      "166/166 [==============================] - 0s 799us/sample - loss: 0.4175 - acc: 0.9759\n",
      "Epoch 277/500\n",
      "166/166 [==============================] - 0s 806us/sample - loss: 0.4149 - acc: 0.9759\n",
      "Epoch 278/500\n",
      "166/166 [==============================] - 0s 855us/sample - loss: 0.4129 - acc: 0.9759\n",
      "Epoch 279/500\n",
      "166/166 [==============================] - 0s 640us/sample - loss: 0.4099 - acc: 0.9759\n",
      "Epoch 280/500\n",
      "166/166 [==============================] - 0s 959us/sample - loss: 0.4065 - acc: 0.9759\n",
      "Epoch 281/500\n",
      "166/166 [==============================] - 0s 974us/sample - loss: 0.4027 - acc: 0.9759\n",
      "Epoch 282/500\n",
      "166/166 [==============================] - 0s 673us/sample - loss: 0.4003 - acc: 0.9759\n",
      "Epoch 283/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 0.3975 - acc: 0.9759\n",
      "Epoch 284/500\n",
      "166/166 [==============================] - 0s 637us/sample - loss: 0.3957 - acc: 0.9759\n",
      "Epoch 285/500\n",
      "166/166 [==============================] - 0s 563us/sample - loss: 0.3925 - acc: 0.9759\n",
      "Epoch 286/500\n",
      "166/166 [==============================] - 0s 670us/sample - loss: 0.3891 - acc: 0.9759\n",
      "Epoch 287/500\n",
      "166/166 [==============================] - 0s 670us/sample - loss: 0.3873 - acc: 0.9759\n",
      "Epoch 288/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.3843 - acc: 0.9759\n",
      "Epoch 289/500\n",
      "166/166 [==============================] - 0s 919us/sample - loss: 0.3828 - acc: 0.9759\n",
      "Epoch 290/500\n",
      "166/166 [==============================] - 0s 817us/sample - loss: 0.3799 - acc: 0.9759\n",
      "Epoch 291/500\n",
      "166/166 [==============================] - 0s 721us/sample - loss: 0.3768 - acc: 0.9759\n",
      "Epoch 292/500\n",
      "166/166 [==============================] - 0s 787us/sample - loss: 0.3742 - acc: 0.9759\n",
      "Epoch 293/500\n",
      "166/166 [==============================] - 0s 703us/sample - loss: 0.3722 - acc: 0.9759\n",
      "Epoch 294/500\n",
      "166/166 [==============================] - 0s 595us/sample - loss: 0.3690 - acc: 0.9699\n",
      "Epoch 295/500\n",
      "166/166 [==============================] - 0s 652us/sample - loss: 0.3674 - acc: 0.9759\n",
      "Epoch 296/500\n",
      "166/166 [==============================] - 0s 619us/sample - loss: 0.3646 - acc: 0.9759\n",
      "Epoch 297/500\n",
      "166/166 [==============================] - 0s 596us/sample - loss: 0.3620 - acc: 0.9759\n",
      "Epoch 298/500\n",
      "166/166 [==============================] - 0s 652us/sample - loss: 0.3595 - acc: 0.9759\n",
      "Epoch 299/500\n",
      "166/166 [==============================] - 0s 703us/sample - loss: 0.3583 - acc: 0.9759\n",
      "Epoch 300/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.3570 - acc: 0.9759\n",
      "Epoch 301/500\n",
      "166/166 [==============================] - 0s 633us/sample - loss: 0.3529 - acc: 0.9759\n",
      "Epoch 302/500\n",
      "166/166 [==============================] - 0s 610us/sample - loss: 0.3528 - acc: 0.9759\n",
      "Epoch 303/500\n",
      "166/166 [==============================] - 0s 884us/sample - loss: 0.3490 - acc: 0.9759\n",
      "Epoch 304/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 0.3468 - acc: 0.9759\n",
      "Epoch 305/500\n",
      "166/166 [==============================] - 0s 728us/sample - loss: 0.3435 - acc: 0.9759\n",
      "Epoch 306/500\n",
      "166/166 [==============================] - 0s 592us/sample - loss: 0.3421 - acc: 0.9759\n",
      "Epoch 307/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 0.3446 - acc: 0.9759\n",
      "Epoch 308/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.3425 - acc: 0.9759\n",
      "Epoch 309/500\n",
      "166/166 [==============================] - 0s 607us/sample - loss: 0.3400 - acc: 0.9759\n",
      "Epoch 310/500\n",
      "166/166 [==============================] - 0s 658us/sample - loss: 0.3374 - acc: 0.9759\n",
      "Epoch 311/500\n",
      "166/166 [==============================] - 0s 706us/sample - loss: 0.3342 - acc: 0.9759\n",
      "Epoch 312/500\n",
      "166/166 [==============================] - 0s 1ms/sample - loss: 0.3317 - acc: 0.9759\n",
      "Epoch 313/500\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3530 - acc: 0.968 - 0s 785us/sample - loss: 0.3305 - acc: 0.9759\n",
      "Epoch 314/500\n",
      "166/166 [==============================] - 0s 561us/sample - loss: 0.3283 - acc: 0.9759\n",
      "Epoch 315/500\n",
      "166/166 [==============================] - 0s 592us/sample - loss: 0.3227 - acc: 0.9759\n",
      "Epoch 316/500\n",
      "166/166 [==============================] - 0s 538us/sample - loss: 0.3214 - acc: 0.9759\n",
      "Epoch 317/500\n",
      "166/166 [==============================] - 0s 602us/sample - loss: 0.3243 - acc: 0.9759\n",
      "Epoch 318/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.3244 - acc: 0.9759\n",
      "Epoch 319/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.3567 - acc: 0.9699\n",
      "Epoch 320/500\n",
      "166/166 [==============================] - 0s 688us/sample - loss: 0.3523 - acc: 0.9759\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 631us/sample - loss: 0.3386 - acc: 0.9759\n",
      "Epoch 322/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 0.3299 - acc: 0.9759\n",
      "Epoch 323/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.3316 - acc: 0.9759\n",
      "Epoch 324/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 0.3335 - acc: 0.9759\n",
      "Epoch 325/500\n",
      "166/166 [==============================] - 0s 709us/sample - loss: 0.3635 - acc: 0.9699\n",
      "Epoch 326/500\n",
      "166/166 [==============================] - 0s 547us/sample - loss: 0.3937 - acc: 0.9458\n",
      "Epoch 327/500\n",
      "166/166 [==============================] - 0s 625us/sample - loss: 0.3991 - acc: 0.9398\n",
      "Epoch 328/500\n",
      "166/166 [==============================] - 0s 629us/sample - loss: 0.4005 - acc: 0.9639\n",
      "Epoch 329/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.3893 - acc: 0.9578\n",
      "Epoch 330/500\n",
      "166/166 [==============================] - 0s 625us/sample - loss: 0.3953 - acc: 0.9458\n",
      "Epoch 331/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.3991 - acc: 0.9398\n",
      "Epoch 332/500\n",
      "166/166 [==============================] - 0s 604us/sample - loss: 0.3929 - acc: 0.9398\n",
      "Epoch 333/500\n",
      "166/166 [==============================] - 0s 610us/sample - loss: 0.3706 - acc: 0.9578\n",
      "Epoch 334/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 0.3811 - acc: 0.9639\n",
      "Epoch 335/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.3458 - acc: 0.9639\n",
      "Epoch 336/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.3413 - acc: 0.9639\n",
      "Epoch 337/500\n",
      "166/166 [==============================] - 0s 595us/sample - loss: 0.3375 - acc: 0.9699\n",
      "Epoch 338/500\n",
      "166/166 [==============================] - 0s 568us/sample - loss: 0.3584 - acc: 0.9518\n",
      "Epoch 339/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.3646 - acc: 0.9458\n",
      "Epoch 340/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.3515 - acc: 0.9639\n",
      "Epoch 341/500\n",
      "166/166 [==============================] - 0s 580us/sample - loss: 0.3711 - acc: 0.9639\n",
      "Epoch 342/500\n",
      "166/166 [==============================] - 0s 670us/sample - loss: 0.3405 - acc: 0.9699\n",
      "Epoch 343/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.3327 - acc: 0.9639\n",
      "Epoch 344/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.3181 - acc: 0.9699\n",
      "Epoch 345/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.3102 - acc: 0.9699\n",
      "Epoch 346/500\n",
      "166/166 [==============================] - 0s 757us/sample - loss: 0.2957 - acc: 0.9759\n",
      "Epoch 347/500\n",
      "166/166 [==============================] - 0s 701us/sample - loss: 0.2908 - acc: 0.9699\n",
      "Epoch 348/500\n",
      "166/166 [==============================] - 0s 686us/sample - loss: 0.2831 - acc: 0.9759\n",
      "Epoch 349/500\n",
      "166/166 [==============================] - 0s 625us/sample - loss: 0.2798 - acc: 0.9759\n",
      "Epoch 350/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.2794 - acc: 0.9759\n",
      "Epoch 351/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.2739 - acc: 0.9759\n",
      "Epoch 352/500\n",
      "166/166 [==============================] - 0s 463us/sample - loss: 0.2715 - acc: 0.9759\n",
      "Epoch 353/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.2684 - acc: 0.9759\n",
      "Epoch 354/500\n",
      "166/166 [==============================] - 0s 864us/sample - loss: 0.2667 - acc: 0.9759\n",
      "Epoch 355/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.2643 - acc: 0.9759\n",
      "Epoch 356/500\n",
      "166/166 [==============================] - 0s 487us/sample - loss: 0.2615 - acc: 0.9759\n",
      "Epoch 357/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.2599 - acc: 0.9759\n",
      "Epoch 358/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.2582 - acc: 0.9759\n",
      "Epoch 359/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 0.2570 - acc: 0.9759\n",
      "Epoch 360/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.2551 - acc: 0.9759\n",
      "Epoch 361/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.2538 - acc: 0.9759\n",
      "Epoch 362/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.2514 - acc: 0.9759\n",
      "Epoch 363/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.2498 - acc: 0.9759\n",
      "Epoch 364/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.2486 - acc: 0.9759\n",
      "Epoch 365/500\n",
      "166/166 [==============================] - 0s 625us/sample - loss: 0.2469 - acc: 0.9759\n",
      "Epoch 366/500\n",
      "166/166 [==============================] - 0s 373us/sample - loss: 0.2455 - acc: 0.9759\n",
      "Epoch 367/500\n",
      "166/166 [==============================] - 0s 421us/sample - loss: 0.2437 - acc: 0.9759\n",
      "Epoch 368/500\n",
      "166/166 [==============================] - 0s 403us/sample - loss: 0.2421 - acc: 0.9759\n",
      "Epoch 369/500\n",
      "166/166 [==============================] - 0s 385us/sample - loss: 0.2405 - acc: 0.9759\n",
      "Epoch 370/500\n",
      "166/166 [==============================] - 0s 379us/sample - loss: 0.2396 - acc: 0.9759\n",
      "Epoch 371/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.2385 - acc: 0.9759\n",
      "Epoch 372/500\n",
      "166/166 [==============================] - 0s 601us/sample - loss: 0.2372 - acc: 0.9759\n",
      "Epoch 373/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.2383 - acc: 0.9759\n",
      "Epoch 374/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.2354 - acc: 0.9759\n",
      "Epoch 375/500\n",
      "166/166 [==============================] - 0s 739us/sample - loss: 0.2347 - acc: 0.9759\n",
      "Epoch 376/500\n",
      "166/166 [==============================] - 0s 889us/sample - loss: 0.2327 - acc: 0.9759\n",
      "Epoch 377/500\n",
      "166/166 [==============================] - 0s 709us/sample - loss: 0.2321 - acc: 0.9759\n",
      "Epoch 378/500\n",
      "166/166 [==============================] - 0s 793us/sample - loss: 0.2306 - acc: 0.9759\n",
      "Epoch 379/500\n",
      "166/166 [==============================] - 0s 799us/sample - loss: 0.2302 - acc: 0.9759\n",
      "Epoch 380/500\n",
      "166/166 [==============================] - 0s 715us/sample - loss: 0.2273 - acc: 0.9759\n",
      "Epoch 381/500\n",
      "166/166 [==============================] - 0s 769us/sample - loss: 0.2263 - acc: 0.9759\n",
      "Epoch 382/500\n",
      "166/166 [==============================] - 0s 739us/sample - loss: 0.2248 - acc: 0.9759\n",
      "Epoch 383/500\n",
      "166/166 [==============================] - 0s 679us/sample - loss: 0.2230 - acc: 0.9759\n",
      "Epoch 384/500\n",
      "166/166 [==============================] - 0s 487us/sample - loss: 0.2216 - acc: 0.9759\n",
      "Epoch 385/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 0.2206 - acc: 0.9759\n",
      "Epoch 386/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.2193 - acc: 0.9759\n",
      "Epoch 387/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.2185 - acc: 0.9759\n",
      "Epoch 388/500\n",
      "166/166 [==============================] - 0s 463us/sample - loss: 0.2171 - acc: 0.9759\n",
      "Epoch 389/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.2155 - acc: 0.9759\n",
      "Epoch 390/500\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.2047 - acc: 0.984 - 0s 565us/sample - loss: 0.2149 - acc: 0.9759\n",
      "Epoch 391/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.2134 - acc: 0.9759\n",
      "Epoch 392/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.2133 - acc: 0.9699\n",
      "Epoch 393/500\n",
      "166/166 [==============================] - 0s 469us/sample - loss: 0.2122 - acc: 0.9759\n",
      "Epoch 394/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.2107 - acc: 0.9759\n",
      "Epoch 395/500\n",
      "166/166 [==============================] - 0s 541us/sample - loss: 0.2091 - acc: 0.9759\n",
      "Epoch 396/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.2083 - acc: 0.9699\n",
      "Epoch 397/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.2073 - acc: 0.9699\n",
      "Epoch 398/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 0.2066 - acc: 0.9699\n",
      "Epoch 399/500\n",
      "166/166 [==============================] - 0s 451us/sample - loss: 0.2060 - acc: 0.9759\n",
      "Epoch 400/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.2052 - acc: 0.9699\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 583us/sample - loss: 0.2035 - acc: 0.9759\n",
      "Epoch 402/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.2018 - acc: 0.9759\n",
      "Epoch 403/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.2011 - acc: 0.9759\n",
      "Epoch 404/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 0.2000 - acc: 0.9759\n",
      "Epoch 405/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.1991 - acc: 0.9699\n",
      "Epoch 406/500\n",
      "166/166 [==============================] - 0s 457us/sample - loss: 0.1978 - acc: 0.9759\n",
      "Epoch 407/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1976 - acc: 0.9759\n",
      "Epoch 408/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.1958 - acc: 0.9759\n",
      "Epoch 409/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1955 - acc: 0.9759\n",
      "Epoch 410/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1945 - acc: 0.9759\n",
      "Epoch 411/500\n",
      "166/166 [==============================] - 0s 457us/sample - loss: 0.1941 - acc: 0.9759\n",
      "Epoch 412/500\n",
      "166/166 [==============================] - 0s 516us/sample - loss: 0.1929 - acc: 0.9759\n",
      "Epoch 413/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1916 - acc: 0.9699\n",
      "Epoch 414/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.1903 - acc: 0.9759\n",
      "Epoch 415/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1895 - acc: 0.9759\n",
      "Epoch 416/500\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.1361 - acc: 1.000 - 0s 439us/sample - loss: 0.1889 - acc: 0.9699\n",
      "Epoch 417/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1880 - acc: 0.9759\n",
      "Epoch 418/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.1870 - acc: 0.9759\n",
      "Epoch 419/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.1861 - acc: 0.9759\n",
      "Epoch 420/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.1851 - acc: 0.9759\n",
      "Epoch 421/500\n",
      "166/166 [==============================] - 0s 541us/sample - loss: 0.1846 - acc: 0.9759\n",
      "Epoch 422/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.1835 - acc: 0.9759\n",
      "Epoch 423/500\n",
      "166/166 [==============================] - 0s 463us/sample - loss: 0.1829 - acc: 0.9759\n",
      "Epoch 424/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1819 - acc: 0.9759\n",
      "Epoch 425/500\n",
      "166/166 [==============================] - 0s 643us/sample - loss: 0.1810 - acc: 0.9759\n",
      "Epoch 426/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.1806 - acc: 0.9759\n",
      "Epoch 427/500\n",
      "166/166 [==============================] - 0s 859us/sample - loss: 0.1798 - acc: 0.9759s - loss: 0.1667 - acc: 0.984\n",
      "Epoch 428/500\n",
      "166/166 [==============================] - 0s 709us/sample - loss: 0.1794 - acc: 0.9759\n",
      "Epoch 429/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1789 - acc: 0.9759\n",
      "Epoch 430/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1775 - acc: 0.9759\n",
      "Epoch 431/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.1772 - acc: 0.9759\n",
      "Epoch 432/500\n",
      "166/166 [==============================] - 0s 487us/sample - loss: 0.1765 - acc: 0.9759\n",
      "Epoch 433/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 0.1747 - acc: 0.9699\n",
      "Epoch 434/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1736 - acc: 0.9759\n",
      "Epoch 435/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.1725 - acc: 0.9759\n",
      "Epoch 436/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1720 - acc: 0.9699\n",
      "Epoch 437/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.1712 - acc: 0.9759\n",
      "Epoch 438/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1702 - acc: 0.9759\n",
      "Epoch 439/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.1696 - acc: 0.9699\n",
      "Epoch 440/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1689 - acc: 0.9759\n",
      "Epoch 441/500\n",
      "166/166 [==============================] - 0s 475us/sample - loss: 0.1678 - acc: 0.9759\n",
      "Epoch 442/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.1671 - acc: 0.9759\n",
      "Epoch 443/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 0.1665 - acc: 0.9759\n",
      "Epoch 444/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.1661 - acc: 0.9759\n",
      "Epoch 445/500\n",
      "166/166 [==============================] - 0s 523us/sample - loss: 0.1653 - acc: 0.9759\n",
      "Epoch 446/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1648 - acc: 0.9759\n",
      "Epoch 447/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.1645 - acc: 0.9759\n",
      "Epoch 448/500\n",
      "166/166 [==============================] - 0s 547us/sample - loss: 0.1636 - acc: 0.9759\n",
      "Epoch 449/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.1629 - acc: 0.9759\n",
      "Epoch 450/500\n",
      "166/166 [==============================] - 0s 547us/sample - loss: 0.1621 - acc: 0.9759\n",
      "Epoch 451/500\n",
      "166/166 [==============================] - 0s 439us/sample - loss: 0.1615 - acc: 0.9759\n",
      "Epoch 452/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.1611 - acc: 0.9759\n",
      "Epoch 453/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1597 - acc: 0.9759\n",
      "Epoch 454/500\n",
      "166/166 [==============================] - 0s 457us/sample - loss: 0.1598 - acc: 0.9759\n",
      "Epoch 455/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 0.1587 - acc: 0.9759\n",
      "Epoch 456/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1582 - acc: 0.9759\n",
      "Epoch 457/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1577 - acc: 0.9759\n",
      "Epoch 458/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.1569 - acc: 0.9759\n",
      "Epoch 459/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.1565 - acc: 0.9759\n",
      "Epoch 460/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1561 - acc: 0.9759\n",
      "Epoch 461/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1555 - acc: 0.9759\n",
      "Epoch 462/500\n",
      "166/166 [==============================] - 0s 547us/sample - loss: 0.1545 - acc: 0.9759\n",
      "Epoch 463/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.1540 - acc: 0.9759\n",
      "Epoch 464/500\n",
      "166/166 [==============================] - 0s 499us/sample - loss: 0.1537 - acc: 0.9759\n",
      "Epoch 465/500\n",
      "166/166 [==============================] - 0s 559us/sample - loss: 0.1527 - acc: 0.9759s - loss: 0.1560 - acc: 0.975\n",
      "Epoch 466/500\n",
      "166/166 [==============================] - 0s 481us/sample - loss: 0.1518 - acc: 0.9759\n",
      "Epoch 467/500\n",
      "166/166 [==============================] - 0s 487us/sample - loss: 0.1518 - acc: 0.9759\n",
      "Epoch 468/500\n",
      "166/166 [==============================] - 0s 547us/sample - loss: 0.1508 - acc: 0.9759\n",
      "Epoch 469/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.1503 - acc: 0.9759\n",
      "Epoch 470/500\n",
      "166/166 [==============================] - 0s 439us/sample - loss: 0.1494 - acc: 0.9759\n",
      "Epoch 471/500\n",
      "166/166 [==============================] - 0s 451us/sample - loss: 0.1491 - acc: 0.9819\n",
      "Epoch 472/500\n",
      "166/166 [==============================] - 0s 451us/sample - loss: 0.1489 - acc: 0.9759\n",
      "Epoch 473/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1485 - acc: 0.9759\n",
      "Epoch 474/500\n",
      "166/166 [==============================] - 0s 565us/sample - loss: 0.1476 - acc: 0.9759\n",
      "Epoch 475/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 0.1473 - acc: 0.9759\n",
      "Epoch 476/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1458 - acc: 0.9759\n",
      "Epoch 477/500\n",
      "166/166 [==============================] - 0s 571us/sample - loss: 0.1455 - acc: 0.9759\n",
      "Epoch 478/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.1453 - acc: 0.9759\n",
      "Epoch 479/500\n",
      "166/166 [==============================] - 0s 589us/sample - loss: 0.1449 - acc: 0.9759\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 517us/sample - loss: 0.1447 - acc: 0.9759\n",
      "Epoch 481/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1446 - acc: 0.9759\n",
      "Epoch 482/500\n",
      "166/166 [==============================] - 0s 643us/sample - loss: 0.1434 - acc: 0.9759\n",
      "Epoch 483/500\n",
      "166/166 [==============================] - 0s 517us/sample - loss: 0.1432 - acc: 0.9759\n",
      "Epoch 484/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1431 - acc: 0.9759\n",
      "Epoch 485/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1423 - acc: 0.9759\n",
      "Epoch 486/500\n",
      "166/166 [==============================] - 0s 529us/sample - loss: 0.1412 - acc: 0.9759\n",
      "Epoch 487/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.1402 - acc: 0.9759\n",
      "Epoch 488/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.1397 - acc: 0.9759\n",
      "Epoch 489/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1393 - acc: 0.9759\n",
      "Epoch 490/500\n",
      "166/166 [==============================] - 0s 505us/sample - loss: 0.1383 - acc: 0.9759\n",
      "Epoch 491/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.1382 - acc: 0.9759\n",
      "Epoch 492/500\n",
      "166/166 [==============================] - 0s 493us/sample - loss: 0.1375 - acc: 0.9759\n",
      "Epoch 493/500\n",
      "166/166 [==============================] - 0s 583us/sample - loss: 0.1370 - acc: 0.9759\n",
      "Epoch 494/500\n",
      "166/166 [==============================] - 0s 553us/sample - loss: 0.1362 - acc: 0.9759\n",
      "Epoch 495/500\n",
      "166/166 [==============================] - 0s 511us/sample - loss: 0.1357 - acc: 0.9759\n",
      "Epoch 496/500\n",
      "166/166 [==============================] - 0s 577us/sample - loss: 0.1354 - acc: 0.9759\n",
      "Epoch 497/500\n",
      "166/166 [==============================] - 0s 853us/sample - loss: 0.1352 - acc: 0.9759\n",
      "Epoch 498/500\n",
      "166/166 [==============================] - 0s 685us/sample - loss: 0.1348 - acc: 0.9759\n",
      "Epoch 499/500\n",
      "166/166 [==============================] - 0s 613us/sample - loss: 0.1340 - acc: 0.9759\n",
      "Epoch 500/500\n",
      "166/166 [==============================] - 0s 535us/sample - loss: 0.1340 - acc: 0.9759\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xs,ys,epochs=500,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history,string):\n",
    "    plt.plot(history.history[string],label=string)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8nWWd9/HPL2nWtmmSNk2XpE03wFLK0lAKyCJ7EUQBFXAEUaeiIvrooPg4I/qM88z4OOqIsogK6IioLGJlKqssIi1dsC1d6L6lS/Y2SbMnv+ePc3pI07RN2ty5c875vl+vvHLf17mT/K5QzjfXvVyXuTsiIiIAKWEXICIig4dCQUREYhQKIiISo1AQEZEYhYKIiMQoFEREJEahICIiMQoFERGJUSiIiEjMkLAL6KtRo0Z5SUlJ2GWIiMSVZcuWVbl7wdGOi7tQKCkpYenSpWGXISISV8xsW2+O0+kjERGJCSwUzOwhM6sws1WHed3M7B4z22hmK83sjKBqERGR3glypPAIcMURXp8LTIt+zAPuD7AWERHphcBCwd1fA2qOcMg1wK88YhGQa2Zjg6pHRESOLsxrCuOBHV32y6JtIiISkjBDwXpo63HFHzObZ2ZLzWxpZWVlwGWJiCSvMEOhDCjusl8E7OrpQHd/0N1L3b20oOCot9mKiMgxCjMU5gM3R+9CmgPsc/fdIdYjItLvVu3cxyvrKsIuo9cCe3jNzB4DLgRGmVkZcDeQBuDuDwALgCuBjUAjcGtQtYgEraW9g521TUwuGHZQe2ens76inpPG5NDZ6SzeWkNLe+dx/ayMISnkZqdRXtfS5681oCgvix21TQAMyxjCrIl5ffoeO2oa6eh0ttU09vnnH4uCYRk0tLTT0t5B6cR8OtyprG9h994m2jqdMTmZ1OxvpbXj3d/r+Nws9uxrZlxuZqyvRzJqWDqNrR3kRX+vY0dkUlbb1PP57D665aHFADz48VlkpKUe1/cqzss65N9YfzP3/uj2wCktLXU90SwDyd1pausgO30ILe0dpJoxJDUFd8cscmnsvlc28v3n1/Pcl85nfG4WWemptLR38OOXNvKTlzfyy0/Opq6pjS889veQe3OoX35yNhec0PNp2a59BKisb+HMf3txoEo7xI2zJ7ChvJ6l22pDqyFMt10whbvmnnRMX2tmy9y99GjHxd00FyID7f88s4aH/7aV62cV8acVuxidk8ETt53De7/7F/71mhncMHsCr2+ooqPTueQHrwLwiXNK+M3i7bRGRwUH/lo0gyduO5ue77PonRsfXERrRye//tRZZKX37S/PB17dxAtryrn76unMLBrBHY8t5+d/3dxjKDy2eDt3/3E1S75xCUu21vDpXx38x9gdF03lghNHH3M/eqOlvYObfvYmAB88bRyPLd4ee218bhb/9qEZfOLhJeRkDuHhW2cDkZHMl363PHbcjbOLuX5WMYfT2t7JjT9bdEj7taeP52NzJh53H7LTU8lKS6V6f+txf6/CnIzj/h5Ho5GCxJ3fL9nBtpr93Hl5z38xPfDqJp5ZuYu01BQ6Op3MtFS+PvckZhblcsdjf+ejZxZz/mH+Mu5u594mLvzey7R1HP7/kxMLh7OpsgEzDjpueMYQvnjJNIrysli9q44f/2UjwzOG8Pa3L+9bh7vZUrWfPfuaOXvKyD5/bUNLOy+/U8FVM8diZtz5+Ape21DJ1TPHcULhcD5yZjG79zXxuUff4u/b9wKRgHvkja2x7/GdD85geOYQ3n/KWIakBn9ZcsnWGvKy0xg1LIOn3tpJaopRmJPBqcW5jB2Rxd82VlGcl82Ekdmxr3l+9R5Om5DLwk3VXH7yGDKPctpm6dYaRmSlsb2mkRnjR7BoczWXTR/T59AdzHo7UlAoSNy57v43eLtsHyu/ddkh/7O7O6d++3nqmtsP+bo5k/NZtDnyPOVNZ03o1c96Z3cdb+/cxyO3zuY3i7dz8UmjeXldJX9aEblRrnRiHqOGZZCaatxydgnPrNxFRV0Lz67ewx0XTeXLl50Y+173v7KJ0yfkMmdy39/Mg/KjFzfwwxfXx/ZXfusyvvvnd3h8aRkzxufwVjQYIPIX9+kT8vhI6eH/6pbBS6ePJCGt3V3Hsuj55Le219LZCedMGUlKilFZ38IzK3f1GAhALBAAnl9d3uuf+dkLpnDu1FGcO3UUAFefOi4WCo/fdvZB59xnT8rnzc3VVNQ388n3Tjr4+1w4pdc/c6CMz8s6aP+19ZU8v6acK2aM4Uc3nMbMbz9PfXM7l04v5N+vnRlSlTKQFAoy6LR3dNIePe3T1b7GNub+6K+x/bv/uJoNFQ187/qZXHnKWD7z30t5a/teUlOMjs7ICDgnc0gsJKaNHkZDSzsLv37xcdWXlprC1NHDaOvoPCgQDjhr8kie+ty5x/UzBkpRt1B4dtUeKutbOHlcDmbGiYXDWbqtlsmjhoZUoQw0hYIMOv/0+AqeXr6LLf9+ZexNd3NlAxd9/9XYMUNSjA0VDQDc+cRK7nxiJQBfuGgqnzinhM8++haLt9Sw8OsXk5pidLrHrjH0hwV3nNcv3ydsE/LfPQ8/JieTZ1ZGHhU6oXA4ADfMnsDSbbVMHKlQSBYKBRl0nl4eOTUz4+7nePmfLuR//X45y7uc2/7+h09lze46fvH6loO+7oYzi/nCRdNIH5LCz28pZXt1I0MzDv4nfpy3icekD0mMpUjG5b47Urjz8hP5yuMrAJg6OnIv/HVnjKcoL4vSPj7LIPFLoSCDwktry9m5t4mbzy6Jte1v7eD6BxayvaaRK08Zw3vG5JCTlcZ1s4qYXdPI2BGZzJqYx8LN1bjDZ86fHLsbJiczjRnjR4TUm/jyl69cwOsbq7j2jPHs2ttESorFTiuZ2aC6MC7B091HMiB21DSypWp/j7eCNrV28J5vPgvA0n++hNLvRB6OmjE+h/YOZ+roYdxzw+mkpBz7vf0iyU53H8mg4e588N6/Ub2/lYc/cSbvO+ngB57e2FQV2757/moAfv+Zs5k9KX9A6xQRrdEsA+CNTdWxpzlvfWQJ26sPnjNnfXlDbPt/Vu7mtOJczizROWyRMGikIIH6yzvlfPKRpRTmZPCVS0/kq0+uZM3ufdQ1t3Hd/W/0ODncL24p7fFWTxEJnkJBAvXsqj0A3HvTGUwfl8NXn1zJhvIGdu5tPiQQ7rnxdOZMymfksODndxGRnikUJFBvbqnh0umFlJZErg8U5WWxvqKBYRmpDMsYwlUzx9LQ0s41p43n0umFIVcrIgoFCczCTdVsq25k3vmTY21nTMjj5XUVjMnJ5ORxOfzHdZo6QWQw0YVmCcyjb25j5NB0rjujKNb2mQsms7+lnQ0VDcws0nMEIoONRgoSCHdn0eZqzj+h4KA5jE4eN4JX73wfDS3tTAl4BSkR6TuFggRiXXk9VQ2tnNXDswbFXebbEZHBRaEg/aqz0/nP59fx6vpKMoakcPF7dPFYJJ4oFOSYVdQ189I7FZREZ9B0d3Kz07nvlU0UDM/gf116AgXDdXupSDxRKMgxu//VTTz8t60HtV0/K3JR+Q+fO4eiPJ0mEok3uvtIjln36SoAnlhWxsSR2QoEkTilkYIcs7Laptj25983hbkzxlJW2xhboEVE4o9CQY6Ju1NW28iHZxUxfVwON59dQmqKaQ0DkTinUJBjsrexjf2tHZw4Zji3njvp6F8gInFB1xSkz9o7OnludWSiu0la0F0koSgUpM8eW7KDu556G4DSiVoIRySRKBSkzzZXvrsozojstBArEZH+pmsKclRPLitj7e465p0/ma89uZKGlnYAFtxxXsiViUh/UyjIUX3l8RUAPL+mnO01kWcTzpqUz/RxOWGWJSIB0OkjOSJ3J2NI5J/JgUAA9HCaSIJSKMgR7ahpOmjZzJzMyODypDF6QE0kEQV6+sjMrgB+BKQCP3f3/+j2+gjg18CEaC3/6e4PB1mT9F5reyfv//FfARg3IpNd+5qZf/t7STGjOD8r5OpEJAiBhYKZpQL3ApcCZcASM5vv7mu6HPZ5YI27X21mBcA6M3vU3VuDqkt6708rdlHf3M5nLpjMHRdNY+3uOkr0XIJIQgtypDAb2OjumwHM7LfANUDXUHBguJkZMAyoAdoDrEl6Yc++Zv79z2uZv2IXudlp3HXFSZgZpSV6JkEk0QV5TWE8sKPLflm0raufAO8BdgFvA190985ux2Bm88xsqZktraysDKpeifrhC+v54/JduMPUgmFEMltEkkGQodDTO4l3278cWA6MA04DfmJmh9zn6O4Punupu5cWFBT0f6VykAWrdnMgB7r/BxORxBZkKJQBxV32i4iMCLq6FXjKIzYCW4CTAqxJjqKxtZ365nZuODPyn27OZJ0yEkkmQV5TWAJMM7NJwE7gBuCmbsdsBy4G/mpmhcCJwOYAa5IjqG5oYdZ3XgQicxp9+rzJTMjX8wgiySSwUHD3djO7HXiOyC2pD7n7ajO7Lfr6A8C/Ao+Y2dtETjd9zd2rgqpJDm9r1X6uu/+N2P7onAymFAwLsSIRCUOgzym4+wJgQbe2B7ps7wIuC7IG6Z2vPrmS6v3v3glcmJMZYjUiEhY90SwA7OyytCbA6OEZIVUiImFSKAi79jaxp675oLYRWZoSWyQZKRSE+1/ZREqXG4iXf/NSPZsgkqQ0dXaSq6xv4XdLdnD9rGI+9d5JgJObnR52WSISEoVCEttR08jnHn2L1o5OrjtjPFNH624jkWSnUEhiH/npQnbvi1xLmFaoqbBFRNcUklZVQ0ssEEAXlkUkQqGQpBZvqYltH1hZTUREp4+S0PbqyLWEzLQUnv3i+WSnp4ZdkogMEgqFJPTi2nIA7rz8JC2aIyIH0XmDJLRoczUT8rOjt6CKiLxLoZBk3thUxYtryzlv2qiwSxGRQUinj5JI7f5WbvrZmwB8+rzJIVcjIoORRgpJZF15PQB3Xz2dSbqWICI9UCgkkQ3RULhixpiQKxGRwUqhkCSeXFbG75buYHjGEMZorQQROQxdU0gCnZ3OPz+9ik53PnDqOM2AKiKHpVBIAjv3NtHU1sF/XHsKN8yeEHY5IjKI6fRREthQEbmWMK1Qs6CKyJFppJDg7nlpA//14noApo7WTKgicmQKhQTm7vzghUggFOdnaSZUETkqhUICcneeemsndc1tsbacTAWCiBydQiEBrS9v4CuPrzio7bMXTgmpGhGJJwqFBFS9v+Wg/U3/90pSU3Qbqogcne4+SkD7GtsO2lcgiEhvKRQSUG23UBAR6S2dPkog68vr2Vq1n71NrQB88txJXDJ9dMhViUg8USgkkHm/WsrW6kauOHkMGUNS+ObV08MuSUTijE4fJZC2Dgfg2dV7yM3WLagi0ncKhQRx8fdfYefepth+blZ6iNWISLxSKCSAjk5nU+X+g9r09LKIHItAQ8HMrjCzdWa20czuOswxF5rZcjNbbWavBllPotpR03hI22kTckOoRETiXWChYGapwL3AXGA6cKOZTe92TC5wH/ABdz8Z+HBQ9SSyDRUNse2f3HQ6s0vy+ewFeoJZRPouyLuPZgMb3X0zgJn9FrgGWNPlmJuAp9x9O4C7VwRYT8LaUhUJhRV3X8aIrDSumjku5IpEJF4FefpoPLCjy35ZtK2rE4A8M3vFzJaZ2c0B1pOwyutayE5PJSdTdxiLyPEJ8l2kp7kVvIefPwu4GMgCFprZIndff9A3MpsHzAOYMEErh3VXUd/C6OEZWmZTRI5bkCOFMqC4y34RsKuHY5519/3uXgW8Bpza/Ru5+4PuXurupQUFBYEVHK/K65oZnZMZdhkikgCCDIUlwDQzm2Rm6cANwPxux/wROM/MhphZNnAWsDbAmhJSZXSkICJyvAILBXdvB24HniPyRv97d19tZreZ2W3RY9YCzwIrgcXAz919VVA1JaryumYKNVIQkX4Q6JVJd18ALOjW9kC3/e8B3wuyjkS2qbKBxtYOxuVmhV2KiCQAPdEc5+79y0Yy01L4wKm6DVVEjp9CIY7tqGnk6eU7+ficiRTomoKI9AOFQhz7+469dDpcN6so7FJEJEEoFOLYztrIrKjFedkhVyIiiUKhEMfKahvJy05jaIaeZBaR/qFQiGNltU0UaZQgIv1IoRDHymobGa9bUUWkHykU4tS+xjY2V+3nPWNzwi5FRBKIQiFOLd5agzvMmZwfdikikkAUCnFq0eZqMoakcGqxVlgTkf7Tq1Awsw+Z2Ygu+7lm9sHgypKjeXNLNadPyCUzLTXsUkQkgfR2pHC3u+87sOPue4G7gylJDsfd+fgv3uSUbz3Hqp11nDVpZNgliUiC6e0N7j2Fh26OH2BltU38dUNVbP9jc7TgkIj0r96OFJaa2Q/MbIqZTTazHwLLgixMDrVoc3Vs+7ozihg9XNNli0j/6m0ofAFoBX4H/B5oAj4fVFHSs0Wba2Lbo3M0AZ6I9L9enQJy9/3AXQHXIkfRdaRQqFlRRSQAvb376AUzy+2yn2dmzwVXlnS3o6aRnXubYvua70hEgtDb00ejonccAeDutcDoYEqSnry5JXLqaNbEPADSh+gRExHpf719Z+k0s9itLmZWAngQBUnPFm2uJjc7jZ/dXMo/njeJuTPGhl2SiCSg3p6D+Abwupm9Gt0/H5gXTEnSkze3VHPWpHzyh6bzjfdPD7scEUlQvRopuPuzQCmwjsgdSF8hcgeSDIB39tSxo6aJOZP1sJqIBKtXIwUz+zTwRaAIWA7MARYCFwVXmkDkKeb33/M6AGdPUSiISLB6e03hi8CZwDZ3fx9wOlAZWFUS09LeSUenc/bkkZw0RtNki0iwehsKze7eDGBmGe7+DnBicGXJAQ0t7QDMPWVMyJWISDLo7YXmsuhzCk8DL5hZLbAruLLkgIbmSCgM03MJIjIAevtE84eim98ys5eBEcCzgVUlMQdGCgoFERkIfX6ncfdXj36U9Jf6AyOFTIWCiARPj8UOcgdGCsMz0kKuRESSgUJhkGtoaQM0UhCRgaFQGMQ6Op17XtoI6JqCiAwMhcIg9vI7FWyp2g/AcI0URGQAKBQGqY5OZ29TW2w/Q7OiisgACPSdxsyuMLN1ZrbRzA67SI+ZnWlmHWZ2fZD1xIu2jk6m/O8F/NPjK2JtZhZiRSKSLAILBTNLBe4F5gLTgRvN7JDpPaPHfRfQoj1RFfUtsW0zmH/7uSFWIyLJJMiRwmxgo7tvdvdW4LfANT0c9wXgSaAiwFriSkVdc2z71KJcZhblHuFoEZH+E2QojAd2dNkvi7bFmNl44EPAAwHWEVdW7dzH37fHFrnjqplaTEdEBk6Qt7T0dBK8+2pt/wV8zd07jnTO3MzmEV3UZ8KECYc9Lt5VNbRw1Y9fj+0v/sbFjB6eGWJFIpJsggyFMqC4y34Rh06iVwr8NhoIo4Arzazd3Z/uepC7Pwg8CFBaWpqQy4Dua2yj9DsvxvZTDEYOzQixIhFJRkGGwhJgmplNAnYCNwA3dT3A3Scd2DazR4BnugdCsnhnT91B+yOy0khN0R1HIjKwArum4O7twO1E7ipaC/ze3Veb2W1mdltQPzdera9oAGB8bhYAJxQOD7McEUlSgT4m6+4LgAXd2nq8qOzunwiylsGssbWdHzy/jqHpqcy//Vz+5Y+r+JerDrl7V0QkcJo7IWRNrR3c9/ImahvbOG/aKEYOy+C+j80KuywRSVIKhZB9a/5qfrc0cufurz45O+RqRCTZaUKdkL24thyAKQVDNZWFiIROoRCi+uY2ahtbmV2SzyO3apQgIuFTKIRoc+V+Oh0+dd4kivOzwy5HREShEKade5sAKM5TIIjI4KBQCElzWwfbqhsBGJ+XFXI1IiIRuvsoBB2dzkn/8iwAOZlDGJGVFnJFIiIRGimEYM2ud6e0GK9TRyIyiGikMIC2VO3n14u2MXJYeqzt7MkjQ6xIRORgCoUB9NGfLqSivoXs9FSy0lKZMzmf2y+aGnZZIiIxCoUB0tzWEVtms7G1g59+fBaXnzwm5KpERA6mawoDpLLLussnj8vhsumFIVYjItIzjRQGSHl03eX//PCpXHTSaE1pISKDkkYKA+TAqaOTx+WQPzT9KEeLiIRDoTAAXl5XwQtrIhPfjR6uJTZFZPDS6aMBcOvDS2LbedkaJYjI4KWRQsDaOjpj25MLhpKidZdFZBDTSCFge/ZFLjDfdsEUPnP+5JCrERE5Mo0UAlZWG5kJ9bxpo8jTBWYRGeQUCgErq43MhFqkmVBFJA4oFAK2ZncdmWkpjMtVKIjI4KdQCNiizTXMmphHWqp+1SIy+OmdKkD1zW28s6eO2SWaCVVE4oNCIUAbKhpwjzzFLCISDxQKAalqaOHa+94AYFrhsJCrERHpHYVCQJ5YVhbbLtLqaiISJxQKAVlZtheAS6cXkqqnmEUkTigUAlDf3MZfN1Rx7Rnj+dnNpWGXIyLSawqFADyxrIz65nY+cU5J2KWIiPSJQiEAK8v2MW5EJjOLcsMuRUSkTxQKAdhQUc/UwuFhlyEi0meBhoKZXWFm68xso5nd1cPrHzOzldGPN8zs1CDrCVpbRyd/fns3GysamDZat6GKSPwJbOpsM0sF7gUuBcqAJWY2393XdDlsC3CBu9ea2VzgQeCsoGoK2p9W7OLLv18BwMyiESFXIyLSd0GupzAb2OjumwHM7LfANUAsFNz9jS7HLwKKAqwncG9sqiZ/aDp//Py5mhVVROJSkKePxgM7uuyXRdsO51PAnwOsJ1Adnc4bG6uYXZJPcX42Zno2QUTiT5Ch0NO7ovd4oNn7iITC1w7z+jwzW2pmSysrK/uxxP6z4O3d7NrXzNWnjgu7FBGRYxZkKJQBxV32i4Bd3Q8ys5nAz4Fr3L26p2/k7g+6e6m7lxYUFARS7PH6n5W7GTcik7kzxoRdiojIMQsyFJYA08xskpmlAzcA87seYGYTgKeAj7v7+gBrCdTexlaeXb2Hs6eMIkVTWohIHAvsQrO7t5vZ7cBzQCrwkLuvNrPboq8/AHwTGAncFz0H3+7ucTcvxCceXgLAuVO1boKIxLcg7z7C3RcAC7q1PdBl+9PAp4OsIShltY185IGF/Nu1p/D2zn2cO3UkH9D1BBGJc4GGQiJ7YU05u/Y1c2t0lPCZ86cwREtuikicUygco6XbagE4e/JI8oemM3tSfsgViYgcP4XCMahqaOGlteV8tLSY714/M+xyRET6jc53HIMHX9tMa3sn8y6YHHYpIiL9SqHQR1UNLfz3wm184NRxTCnQpHciklgUCn30yN+20tzewe0XTQu7FBGRfqdQ6KPFW2s4vTiXqZoaW0QSkEKhD9ydDeX1nDhGC+iISGJSKPRB9f5WahvbmDZaoSAiiUmh0Afv7K4HYFqhTh2JSGJSKPTB4q01pBicVpwbdikiIoFQKBzFj17cwO2/eYt9jW0s2lTNjPEjGJ6ZFnZZIiKB0BPNR9DZ6fzwxciM3m0dnSzeWsOXLz0h5KpERIKjUOhBR6ezs7aJjLR3B1LPrS5neOYQbjmnJLzCREQCptNHPZi/Yifnf+9lfr1oGwBfu+IkUgw+9d5JjMjSqSMRSVwaKfRgZ20TAD/+y0YALnnPaObOGENxfnaYZYmIBE6h0IP9rR0H7Y/PyyI7Xb8qEUl8On3Ug5qG1oP2FQgikiyS8t1u7e469uxr5sITC4iuDR2zbFstVQ0tjB2RyYisNO6++uSQqhQRGXhJFwodnc7cH/0VgCc/ezazJr67YtqSrTV8+IGFAJw7dSSPfnpOKDWKiIQl6U4fvbOnLra9NjptxQFbKvfHtvOHZgxYTSIig0XShcKbm2ti2//89Cquve9vNLa2A7CxsiH22sih6QNem4hI2JIuFNbsrmPUsHdHAW9t38uji7YDsL48MnK44cxiPlJaHEp9IiJhSrprChsqGjihcBhfumQamyob2FDewE9f24QZ/G1jFbecPZFvXzMj7DJFREKRVKHg7mwsr+fDpcX8w5yJQORuo4/8dCHf+Z+1ZKen8o/nTw65ShGR8CRVKKzeVcf+1g5OKHx3kZxZE/N4+1uX0dreSWZaKplpqSFWKCISrqQKhYde38LwjCG8/5SxB7Vnpw8hW9eVRUSS60Lz+op6ZpXkMSJbk9qJiPQkqUKhoq6FwuGZYZchIjJoJU0odHQ6VQ0tjM7RQ2kiIoeTNKFQ3dBCp8PoHI0UREQOJ2lCobyuBYDRwzVSEBE5nEBDwcyuMLN1ZrbRzO7q4XUzs3uir680szOCqqWivhmAQo0UREQOK7BQMLNU4F5gLjAduNHMpnc7bC4wLfoxD7g/qHpGZKVx+cmFjMtVKIiIHE6QzynMBja6+2YAM/stcA2wpssx1wC/cncHFplZrpmNdffd/V1MaUk+pSX5Rz9QRCSJBXn6aDywo8t+WbStr8dgZvPMbKmZLa2srOz3QkVEJCLIULAe2vwYjsHdH3T3UncvLSgo6JfiRETkUEGGQhnQdf7pImDXMRwjIiIDJMhQWAJMM7NJZpYO3ADM73bMfODm6F1Ic4B9QVxPEBGR3gnsQrO7t5vZ7cBzQCrwkLuvNrPboq8/ACwArgQ2Ao3ArUHVIyIiRxfoLKnuvoDIG3/Xtge6bDvw+SBrEBGR3kuaJ5pFROToFAoiIhJjkTM48cPMKoFtx/jlo4CqfiwnHqjPyUF9Tg7H0+eJ7n7Ue/rjLhSOh5ktdffSsOsYSOpzclCfk8NA9Fmnj0REJEahICIiMckWCg+GXUAI1OfkoD4nh8D7nFTXFERE5MiSbaQgIiJHkDShcLRV4OKVmT1kZhVmtqpLW76ZvWBmG6Kf87q89vXo72CdmV0eTtXHx8yKzexlM1trZqvN7IvR9oTtt5llmtliM1sR7fO3o+0J22eILNZlZn83s2ei+wndXwAz22pmb5vZcjNbGm0buH67e8J/EJl7aRMwGUgHVgDTw66rn/p2PnAGsKpL2/8D7opu3wV8N7o9Pdr3DGBS9HeSGnYfjqHPY4EzotvDgfXRviVsv4lMMz8sup0GvAnMSeQ+R/vxZeA3wDPR/YTub7QvW4FR3doGrN/JMlKIrQLn7q3AgVXg4p67vwbUdGv4OPg8AAADq0lEQVS+BvhldPuXwAe7tP/W3VvcfQuRiQhnD0ih/cjdd7v7W9HtemAtkcWZErbfHtEQ3U2LfjgJ3GczKwLeD/y8S3PC9vcoBqzfyRIKvVrhLYEUenQK8ujn0dH2hPs9mFkJcDqRv5wTut/RUynLgQrgBXdP9D7/F/BVoLNLWyL39wAHnjezZWY2L9o2YP0OdJbUQaRXK7wlgYT6PZjZMOBJ4EvuXmfWU/cih/bQFnf9dvcO4DQzywX+YGYzjnB4XPfZzK4CKtx9mZld2Jsv6aEtbvrbzbnuvsvMRgMvmNk7Rzi23/udLCOFZFvhrdzMxgJEP1dE2xPm92BmaUQC4VF3fyranPD9BnD3vcArwBUkbp/PBT5gZluJnO69yMx+TeL2N8bdd0U/VwB/IHI6aMD6nSyh0JtV4BLJfOCW6PYtwB+7tN9gZhlmNgmYBiwOob7jYpEhwS+Ate7+gy4vJWy/zawgOkLAzLKAS4B3SNA+u/vX3b3I3UuI/P/6F3f/BxK0vweY2VAzG35gG7gMWMVA9jvsK+0DeEX/SiJ3qWwCvhF2Pf3Yr8eA3UAbkb8aPgWMBF4CNkQ/53c5/hvR38E6YG7Y9R9jn99LZIi8Elge/bgykfsNzAT+Hu3zKuCb0faE7XOXflzIu3cfJXR/idwhuSL6sfrAe9VA9ltPNIuISEyynD4SEZFeUCiIiEiMQkFERGIUCiIiEqNQEBGRGIWCSDdm1hGdofLAR7/NqmtmJV1ntBUZbJJlmguRvmhy99PCLkIkDBopiPRSdJ7770bXNVhsZlOj7RPN7CUzWxn9PCHaXmhmf4iugbDCzM6JfqtUM/tZdF2E56NPKIsMCgoFkUNldTt99NEur9W5+2zgJ0Rm8SS6/St3nwk8CtwTbb8HeNXdTyWy5sXqaPs04F53PxnYC1wXcH9Eek1PNIt0Y2YN7j6sh/atwEXuvjk6Id8edx9pZlXAWHdvi7bvdvdRZlYJFLl7S5fvUUJk2utp0f2vAWnu/p3geyZydBopiPSNH2b7cMf0pKXLdge6tieDiEJBpG8+2uXzwuj2G0Rm8gT4GPB6dPsl4LMQWyAnZ6CKFDlW+gtF5FBZ0RXODnjW3Q/clpphZm8S+YPqxmjbHcBDZnYnUAncGm3/IvCgmX2KyIjgs0RmtBUZtHRNQaSXotcUSt29KuxaRIKi00ciIhKjkYKIiMRopCAiIjEKBRERiVEoiIhIjEJBRERiFAoiIhKjUBARkZj/D4E1py9imVTKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history,'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nor the division of a battle knows knows knows knows knows knows propose ones the propose election election election election election practise man man his proof proof proof seen the election election election election practise proof man man his proof proof proof seen the election election election election practise proof man man his proof proof proof\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Nor the division of a battle\"\n",
    "for _ in range(50):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list],maxlen=max_seq_len-1,padding='pre')\n",
    "    predicted = model.predict_classes(token_list,verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index==predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \"+output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
